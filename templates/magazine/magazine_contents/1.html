<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>机器学习基础算法与实践</title>
    <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; color: #333;  margin: 0 auto; padding: 20px; }
        .article-header { margin-bottom: 40px; }
        .article-title { font-size: 2.5em; }
        .article-meta { font-size: 0.9em; color: #666; }
        .meta-item { margin-right: 15px; }
        .article-summary { background-color: #f8f9fa; border-radius: 8px; padding: 20px; }
        .summary-title { font-size: 1.2em; }
        .row { display: flex; }
        .col-md-3 { flex: 0 0 25%; max-width: 25%; }
        .col-md-9 { flex: 0 0 75%; max-width: 75%; padding-left: 20px; }
        .toc-container { background-color: #f8f9fa; padding: 20px; border-radius: 8px; position: sticky; top: 20px; }
        .toc-title { font-size: 1.2em; margin-bottom: 10px; }
        .toc-list { list-style: none; padding: 0; }
        .toc-link { text-decoration: none; color: #007bff; display: block; margin-bottom: 5px; }
        .article-section { margin-bottom: 40px; }
        .section-title { font-size: 1.8em; border-bottom: 2px solid #eee; padding-bottom: 10px; }
        .subsection-title { font-size: 1.4em; margin-top: 20px; }
        .section-text { margin-bottom: 15px; }
        .section-list { margin-bottom: 15px; }
        .math-equation { background-color: #f8f9fa; padding: 10px; border-radius: 4px; text-align: center; font-style: italic; }
        .image-container { text-align: center; }
        .article-image { max-width: 100%; height: auto; border-radius: 8px; }
        .image-caption { font-style: italic; color: #666; margin-top: 5px; }
        .code-block { background-color: #f8f9fa; padding: 15px; border-radius: 4px; overflow-x: auto; }
        code { font-family: Consolas, monospace; }
        pre { margin: 0; }
    </style>
</head>
<body>

<!-- 文章头部信息 -->
<header class="article-header mb-10 text-center">
    <h1 class="article-title mb-4">机器学习基础算法与实践</h1>
    <div class="article-meta mb-6">
        <span id="published_at" class="meta-item">发布日期: 2024年5月15日</span>
        <span id="author" class="meta-item">作者: 李睿远</span>
        <span id="read_time" class="meta-item">阅读时间: 15分钟</span> <!-- 更新阅读时间以反映新增内容 -->
    </div>
    <div class="article-summary max-w-3xl mx-auto p-4 bg-light rounded">
        <h3 class="summary-title mb-2">摘要</h3>
        <p>本文介绍了机器学习的基础算法，包括线性回归、逻辑回归和决策树等，并通过实际代码示例展示了这些算法的应用。我们将探讨每种算法的原理、优缺点及适用场景，帮助读者快速掌握机器学习的核心概念和实践技能。本文还新增了决策树的代码实现示例，并补充了各算法的优缺点分析，以提供更全面的理解。</p> <!-- 更新摘要以反映完善 -->
    </div>
</header>

<div class="row">
    <!-- 左侧目录 -->
    <aside class="col-md-3 mb-8">
        <div class="toc-container sticky-top">
            <h3 class="toc-title">目录</h3>
            <ul class="toc-list">
                <li><a href="#intro" class="toc-link">引言</a></li>
                <li><a href="#linear-regression" class="toc-link">线性回归</a></li>
                <li><a href="#logistic-regression" class="toc-link">逻辑回归</a></li>
                <li><a href="#decision-tree" class="toc-link">决策树</a></li>
                <li><a href="#implementation" class="toc-link">代码实现</a></li>
                <li><a href="#conclusion" class="toc-link">结论</a></li>
            </ul>
        </div>
    </aside>

    <!-- 右侧内容区 -->
    <article class="col-md-9 article-content">
        <!-- 引言部分 -->
        <section id="intro" class="article-section mb-10">
            <h2 class="section-title">引言</h2>
            <p class="section-text">机器学习是人工智能的一个重要分支，它使计算机能够从数据中学习并改进，而无需显式编程。近年来，机器学习在各个领域都取得了显著的成果，从图像识别到自然语言处理，从推荐系统到自动驾驶。</p>
            <p class="section-text">本文将介绍几种最基础也最常用的机器学习算法，包括：</p>
            <ul class="section-list">
                <li>线性回归 - 用于预测连续值</li>
                <li>逻辑回归 - 用于二分类问题</li>
                <li>决策树 - 可用于分类和回归</li>
            </ul>
            <p class="section-text">这些算法是理解更复杂模型（如神经网络、集成学习）的基础，掌握它们对于深入学习机器学习至关重要。</p>
        </section>

        <!-- 线性回归部分 -->
        <section id="linear-regression" class="article-section mb-10">
            <h2 class="section-title">线性回归</h2>
            <p class="section-text">线性回归是一种用于预测连续目标变量的监督学习算法。它假设特征与目标变量之间存在线性关系，可以用以下公式表示：</p>
            
            <div class="math-equation mb-4">
                \( y = w_0 + w_1x_1 + w_2x_2 + ... + w_nx_n + \epsilon \)
            </div>
            
            <p class="section-text">其中，\( y \) 是目标变量，\( x_1, x_2, ..., x_n \) 是特征，\( w_0, w_1, ..., w_n \) 是模型参数（权重），\( \epsilon \) 是误差项。</p>
            
            <h3 class="subsection-title">线性回归的目标</h3>
            <p class="section-text">线性回归的目标是找到一组权重，使得预测值与实际值之间的误差最小化。常用的误差度量是均方误差（MSE）：</p>
            
            <div class="math-equation mb-4">
                \( MSE = \frac{1}{m} \sum_{i=1}^{m} (y_i - \hat{y}_i)^2 \)
            </div>
            
            <p class="section-text">其中，\( m \) 是样本数量，\( y_i \) 是实际值，\( \hat{y}_i \) 是预测值。</p>
            
            <!-- 新增优缺点 -->
            <h3 class="subsection-title">优缺点</h3>
            <ul class="section-list">
                <li>优点：简单易懂，计算效率高，解释性强。</li>
                <li>缺点：假设线性关系，对非线性数据表现差，易受异常值影响。</li>
            </ul>
            
            <div class="image-container mb-6">
                <img src="https://picsum.photos/800/400?random=2" alt="线性回归示例图" class="article-image">
                <p class="image-caption">图2: 线性回归拟合数据点的示例，显示了回归线与散点图</p>
            </div>
        </section>

        <!-- 逻辑回归部分 -->
        <section id="logistic-regression" class="article-section mb-10">
            <h2 class="section-title">逻辑回归</h2>
            <p class="section-text">尽管名字中带有"回归"，但逻辑回归实际上是一种用于二分类问题的算法。它通过sigmoid函数将线性回归的输出映射到0和1之间，得到样本属于某一类别的概率。</p>
            
            <h3 class="subsection-title">Sigmoid函数</h3>
            <p class="section-text">Sigmoid函数的定义如下：</p>
            
            <div class="math-equation mb-4">
                \( \sigma(z) = \frac{1}{1 + e^{-z}} \)
            </div>
            
            <p class="section-text">其中，\( z = w_0 + w_1x_1 + ... + w_nx_n \) 是线性组合。Sigmoid函数的输出范围是(0, 1)，可以解释为概率。</p>
            
            <div class="image-container mb-6">
                <img src="https://picsum.photos/800/400?random=1" alt="Sigmoid函数图像" class="article-image">
                <p class="image-caption">图1: Sigmoid函数图像，显示了输入值与输出概率之间的关系</p>
            </div>
            
            <!-- 新增优缺点 -->
            <h3 class="subsection-title">优缺点</h3>
            <ul class="section-list">
                <li>优点：输出概率值，易于解释，对二分类问题有效。</li>
                <li>缺点：假设线性决策边界，对多分类需扩展，易过拟合。</li>
            </ul>
        </section>

        <!-- 决策树部分 -->
        <section id="decision-tree" class="article-section mb-10">
            <h2 class="section-title">决策树</h2>
            <p class="section-text">决策树是一种树形结构的预测模型，它通过一系列决策规则对数据进行分类或回归。决策树由节点和边组成，每个内部节点代表一个特征上的测试，每个分支代表测试的结果，每个叶节点代表一个类别或预测值。</p>
            
            <h3 class="subsection-title">决策树的构建</h3>
            <p class="section-text">决策树的构建过程是一个递归选择最佳特征进行分裂的过程。常用的特征选择准则有：</p>
            <ol class="section-list">
                <li>信息增益（ID3算法）</li>
                <li>增益率（C4.5算法）</li>
                <li>Gini指数（CART算法）</li>
            </ol>
            
            <p class="section-text">信息增益基于香农熵的概念，熵是衡量数据集纯度的指标：</p>
            
            <div class="math-equation mb-4">
                \( H(D) = -\sum_{k=1}^{K} \frac{|C_k|}{|D|} \log_2 \frac{|C_k|}{|D|} \)
            </div>
            
            <p class="section-text">其中，\( D \) 是数据集，\( C_k \) 是数据集 \( D \) 中属于第 \( k \) 类的样本子集。</p>
            
            <!-- 新增优缺点 -->
            <h3 class="subsection-title">优缺点</h3>
            <ul class="section-list">
                <li>优点：易于理解和可视化，无需数据归一化，可处理非线性关系。</li>
                <li>缺点：易过拟合，计算复杂度高，对噪声敏感。</li>
            </ul>
            
            <div class="image-container mb-6">
                <img src="https://picsum.photos/800/400?random=3" alt="决策树示例图" class="article-image">
                <p class="image-caption">图3: 决策树结构示例，展示了节点分裂过程</p>
            </div>
        </section>

        <!-- 代码实现部分 -->
        <section id="implementation" class="article-section mb-10">
            <h2 class="section-title">代码实现</h2>
            <p class="section-text">下面我们使用Python和scikit-learn库实现上述三种算法。首先，我们需要导入必要的库：</p>
            
            <div class="code-block mb-6">
                <pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import mean_squared_error, accuracy_score</code></pre>
            </div>
            
            <h3 class="subsection-title">线性回归实现</h3>
            <p class="section-text">我们使用一个简单的数据集来演示线性回归：</p>
            
            <div class="code-block mb-6">
                <pre><code class="language-python"># 生成示例数据
np.random.seed(42)
X = np.random.rand(100, 1) * 10
y = 2 * X + 5 + np.random.randn(100, 1) * 2

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 创建并训练模型
model = LinearRegression()
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 评估
mse = mean_squared_error(y_test, y_pred)
print(f"均方误差: {mse:.2f}")
print(f"回归系数: {model.coef_[0][0]:.2f}")
print(f"截距: {model.intercept_[0]:.2f}")</code></pre>
            </div>
            
            <h3 class="subsection-title">逻辑回归实现</h3>
            <p class="section-text">逻辑回归的实现与线性回归类似，但用于分类问题：</p>
            
            <div class="code-block mb-6">
                <pre><code class="language-python"># 生成二分类示例数据
from sklearn.datasets import make_classification

X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, random_state=42)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 创建并训练模型
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 评估
accuracy = accuracy_score(y_test, y_pred)
print(f"准确率: {accuracy:.2f}")</code></pre>
            </div>
            
            <!-- 新增决策树实现 -->
            <h3 class="subsection-title">决策树实现</h3>
            <p class="section-text">决策树可用于分类问题，这里我们使用与逻辑回归类似的数据集演示：</p>
            
            <div class="code-block mb-6">
                <pre><code class="language-python"># 使用相同的二分类示例数据
X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, random_state=42)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 创建并训练模型
model = DecisionTreeClassifier(max_depth=5, random_state=42)  # 设置最大深度以避免过拟合
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 评估
accuracy = accuracy_score(y_test, y_pred)
print(f"准确率: {accuracy:.2f}")</code></pre>
            </div>
        </section>

        <!-- 结论部分 -->
        <section id="conclusion" class="article-section mb-10">
            <h2 class="section-title">结论</h2>
            <p class="section-text">本文介绍了三种基础的机器学习算法：线性回归、逻辑回归和决策树。这些算法虽然简单，但在很多实际问题中仍然表现出色，并且是理解更复杂模型的基础。</p>
            <p class="section-text">每种算法都有其适用场景：</p>
            <ul class="section-list">
                <li>线性回归适用于预测连续值，如房价、温度等</li>
                <li>逻辑回归适用于二分类问题，如垃圾邮件识别、疾病预测等</li>
                <li>决策树可用于分类和回归，且结果易于解释</li>
            </ul>
            <p class="section-text">在实际应用中，我们需要根据具体问题和数据特点选择合适的算法，并通过交叉验证等方法评估模型性能。建议读者通过实践代码进一步实验这些算法，并探索高级主题如随机森林和梯度提升机。</p> <!-- 更新结论以提供更多建议 -->
        </section>
    </article>
</div>

</body>
</html>